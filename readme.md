# UDPRN Intersection

## Brief Summary
Write a program which when given two files:
* Calculate the total and distinct count of the udprn values in each file
* Calculate distinct overlap between the values in each file
* Calculate the total overlap between the values in those files

Files will be csv and follow the below structure: <br>
udprn <br>
12312312 <br>
32132132 <br>
... <br>


## Installation + Running Instructions
Requirements:
* Git
* Docker
* Docker-compose


Steps:
* Clone the repo with git
* Manually put two files to compare into the data folder 
* Ensure docker machine is running
* Navigate to folder in terminal and enter "docker-compose up"
* Send a http get request to the docker container running (e.g. http://localhost:8080/intersection?fileA=A_f&fileB=B_f)
* This will process files A_f.csv and B_f.csv and return results
* You can then call another end point (http://localhost:8080/results) to retrieve results from previous files processed


## Implementation


Initially made it work "in-memory" but was quick to implement and I didn't think it would scale so tried to implement using a database. I took timings and recorded the results to compare the two implementations. "in memory" ran quickly with the given test files, but would struggle with larger files.

Results for "memory" version
* Distinct udprns in A_f
* 72791
* Total in A_f
* 86526
* Distinct udprns in B_f
* 72806
* Total in B_f
* 72838
* Total overlap is:
* 69261
* Total distinct overlap is:
* 58212
---
* Time: 0.112479016

<br>

The "database" version took longer than the "in memory" version thinking it should allow for larger file sizes. Also allows more control over storing/maintaining results. 
<br><br> 

I set this up as an express app at this point so it could be more flexible in terms of which files were loaded, seems like a more useful form:
* Have some way of uploading files to the folder
* One end point to tell the service to look through the files and store the results
* Another end point to fetch the results (I've set up an end point to retrieve results but left it very basic)
  <br><br>

Results of "database" version:
* Distinct udprns in A_f
* 72791
* Total in A_f
* 86526
* Distinct udprns in B_f
* 72806
* Total in B_f
* 72838
* Total overlap is:
* 69261
* Total distinct overlap is:
* 58212
---
* Time: 1.801465315

<br><br>

In the end I put the in-memory solution back in as the database solution took far longer with longer file sizes. It was easy to move the in-memory solution in place of the db solutions, and keep the storing results in a table for later retrieval. Since I'm using a map I don't think loading larger files should prove too much of an issue for memory, but would start to cause problems still in terms of time taken (took ~60s to run "long" files generated by the JS file in the data folder). <br>

The in-memory solution streams the file into a map, counting the total number of udprns loaded as it does. It uses the size of the map to see the distinct number of udprns in one file. To find the distinct overlap a new set is created only containing the udprns which exist in both files. The total overlap is calculated by looping through this new set of overlapping udprns and finding how many times each appears in the two files. The result is then stored in a basic format in the results table in a postgres database.